log_level = "DEBUG"
batch_size = 4

[model]
modals = ["T", "A", "V"]
feature_sizes = [768, 256, 32]
encoders = [
    "roberta-large",
    "facebook/wav2vec2-base-960h",
    "google/vivit-b-16x2-kinetics400",
]
fusion = "LowRankFusionLayer({'text': 768, 'audio': 256, 'video': 32}, 16, 128)"
freeze_backbone = true

[dataset]
path = "datasets/MELD"
label_type = "emotion"
