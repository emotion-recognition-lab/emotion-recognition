name = "ablation"
resources = "gpus"

[tasks.unimodal]
command = "uv run emotion-recognize train"
args = [
    "configs/dataset/{dataset}.toml",
    "configs/encoders/T.toml",
    "configs/losses/classification/focal.toml",
    "--seed {seed}",
]

[tasks.unimodal.matrix]
dataset = ["MELD--E", "IEMOCAP--E"]
seed = ["0", "114"]

[tasks.meld-losses]
command = "uv run emotion-recognize train"
args = [
    "configs/dataset/MELD--E.toml",
    "configs/encoders/T+A+V.toml",
    "configs/fusion/DFA-meld.toml",
    "configs/losses/classification/focal.toml",
    "{extra}",
    "--seed 114",
]
deps = ["unimodal"]
[tasks.meld-losses.matrix]
extra = [
    "configs/losses/frl-meld.toml",
    "--teacher-checkpoint checkpoints/training/MELD--E/trainable--2--focal/1xE--T/ce200638--114",
]

[tasks.meld-model]
command = "uv run emotion-recognize train"
args = [
    "configs/dataset/MELD--E.toml",
    "configs/encoders/T+A+V.toml",
    "configs/fusion/{fusion}.toml",
    "configs/losses/classification/focal.toml",
    "configs/losses/frl-meld.toml",
    "--teacher-checkpoint checkpoints/training/MELD--E/trainable--2--focal/1xE--T/ce200638--114",
    "--seed 114",
]
deps = ["unimodal"]
[tasks.meld-model.matrix]
fusion = ["vallina", "shared-meld", "private", "DF-meld"]

[tasks.meld-modality]
command = "uv run emotion-recognize train"
args = [
    "configs/dataset/MELD--E.toml",
    "configs/encoders/{encoder}.toml",
    "configs/fusion/DFA-meld.toml",
    "configs/losses/classification/focal.toml",
    "configs/losses/frl-meld.toml",
    "--teacher-checkpoint checkpoints/training/MELD--E/trainable--2--focal/1xE--T/ce200638--114",
    "--seed 114",
]
deps = ["unimodal"]
[tasks.meld-modality.matrix]
encoder = ["T+A", "T+V"]

[tasks.iemocap-losses]
command = "uv run emotion-recognize train"
args = [
    "configs/dataset/IEMOCAP--E.toml",
    "configs/encoders/T+A+V.toml",
    "configs/fusion/DFA-iemocap.toml",
    "configs/losses/classification/focal.toml",
    "{extra}",
    "--seed 0",
]
deps = ["unimodal"]
[tasks.iemocap-losses.matrix]
extra = [
    "configs/losses/frl-iemocap.toml",
    "--teacher-checkpoint checkpoints/training/IEMOCAP--E/trainable--4--focal/1xE--T/ce200638--114",
]

[tasks.iemocap-model]
command = "uv run emotion-recognize train"
args = [
    "configs/dataset/IEMOCAP--E.toml",
    "configs/encoders/T+A+V.toml",
    "configs/fusion/{fusion}.toml",
    "configs/losses/classification/focal.toml",
    "configs/losses/frl-iemocap.toml",
    "--teacher-checkpoint checkpoints/training/IEMOCAP--E/trainable--4--focal/1xE--T/ce200638--114",
    "--seed 0",
]
deps = ["unimodal"]
[tasks.iemocap-model.matrix]
fusion = ["vallina", "shared-iemocap", "private", "DF-iemocap"]

[tasks.iemocap-modality]
command = "uv run emotion-recognize train"
args = [
    "configs/dataset/IEMOCAP--E.toml",
    "configs/encoders/{encoder}.toml",
    "configs/fusion/DFA-iemocap.toml",
    "configs/losses/classification/focal.toml",
    "configs/losses/frl-iemocap.toml",
    "--teacher-checkpoint checkpoints/training/IEMOCAP--E/trainable--4--focal/1xE--T/ce200638--114",
    "--seed 0",
]
deps = ["unimodal"]
[tasks.iemocap-modality.matrix]
encoder = ["T+A", "T+V"]
